{
  "nodes": [
    {
      "id": "llmChain_0",
      "position": {
        "x": 1466.5614094418997,
        "y": 227.0555358677925
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_0",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_0-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_0-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_0-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_0-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "prompt": "{{promptTemplate_0.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": "Query Chain"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_0-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "outputPrediction"
        },
        "selected": false
      },
      "width": 300,
      "height": 507,
      "selected": false,
      "positionAbsolute": {
        "x": 1466.5614094418997,
        "y": 227.0555358677925
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 920.4554154674267,
        "y": -30.329675038940223
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 3,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-streaming-boolean"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmBlockThreshold-multiOptions"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.0-flash-001",
          "customModelName": "",
          "temperature": "0.5",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": 920.4554154674267,
        "y": -30.329675038940223
      },
      "dragging": false
    },
    {
      "id": "customFunction_0",
      "position": {
        "x": 597.9856956890158,
        "y": 690.7358212899138
      },
      "type": "customNode",
      "data": {
        "id": "customFunction_0",
        "label": "Custom JS Function",
        "version": 3,
        "name": "customFunction",
        "type": "CustomFunction",
        "baseClasses": [
          "CustomFunction",
          "Utilities"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Execute custom javascript function",
        "inputParams": [
          {
            "label": "Input Variables",
            "name": "functionInputVariables",
            "description": "Input variables can be used in the function with prefix $. For example: $var",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "customFunction_0-input-functionInputVariables-json"
          },
          {
            "label": "Function Name",
            "name": "functionName",
            "type": "string",
            "optional": true,
            "placeholder": "My Function",
            "id": "customFunction_0-input-functionName-string"
          },
          {
            "label": "Javascript Function",
            "name": "javascriptFunction",
            "type": "code",
            "id": "customFunction_0-input-javascriptFunction-code"
          }
        ],
        "inputAnchors": [
          {
            "label": "Additional Tools",
            "description": "Tools can be used in the function with $tools.{tool_name}.invoke(args)",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "customFunction_0-input-tools-Tool"
          }
        ],
        "inputs": {
          "functionInputVariables": "",
          "functionName": "schemaTabel",
          "tools": "",
          "javascriptFunction": "const HOST = 'localhost';\nconst USER = 'root';\nconst PASSWORD = '';\nconst DATABASE = 'rehatin_v2';\nconst TABLE = 'tempat_wisata';\nconst mysql = require('mysql2/promise');\n\nlet sqlSchemaPrompt;\n\nfunction getSQLPrompt(userQuestion) {\n  return new Promise(async (resolve, reject) => {\n    try {\n      const singleStoreConnection = mysql.createPool({\n        host: HOST,\n        user: USER,\n        password: PASSWORD,\n        database: DATABASE,\n      });\n\n      // Kolom yang ingin di-exclude\n      const excludedColumns = ['gambar_path', 'gambar_map', 'link_map'];\n\n      // Ambil angka dari pertanyaan user, misalnya: \"Tampilkan 5 tempat wisata\"\n      const match = userQuestion.match(/(\\d+)/);\n      const limitFromUser = match ? parseInt(match[1]) : 3; // Default 3 kalau gak ada angka\n\n      // Ambil informasi schema\n      const [schemaInfo] = await singleStoreConnection.execute(\n        `SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name = \"${TABLE}\"`\n      );\n\n      const createColumns = [];\n      const columnNames = [];\n\n      for (const schemaData of schemaInfo) {\n        const colName = schemaData['COLUMN_NAME'];\n        if (excludedColumns.includes(colName)) continue;\n\n        columnNames.push(colName);\n        createColumns.push(\n          `${colName} ${schemaData['COLUMN_TYPE']} ${schemaData['IS_NULLABLE'] === 'NO' ? 'NOT NULL' : ''}`\n        );\n      }\n\n      // Query untuk ambil data contoh berdasarkan rating dan limit\n      const sqlCreateTableQuery = `CREATE TABLE ${TABLE} (${createColumns.join(', ')})`;\n      const sqlSelectTableQuery = `SELECT ${columnNames.join(', ')} FROM ${TABLE} ORDER BY rating DESC LIMIT ${limitFromUser}`;\n\n      // Ambil datanya\n      const [rows] = await singleStoreConnection.execute(sqlSelectTableQuery);\n\n      const allValues = [];\n      for (const row of rows) {\n        const rowValues = [];\n        for (const colName of columnNames) {\n          rowValues.push(row[colName]);\n        }\n        allValues.push(rowValues.join(' '));\n      }\n\n      // Gabungkan semua jadi prompt string\n      sqlSchemaPrompt =\n        sqlCreateTableQuery +\n        '\\n' +\n        sqlSelectTableQuery +\n        '\\n' +\n        columnNames.join(' ') +\n        '\\n' +\n        allValues.join('\\n');\n\n      resolve(sqlSchemaPrompt);\n    } catch (e) {\n      console.error(e);\n      return reject(e);\n    }\n  });\n}\n\n// Contoh penggunaan\nasync function main() {\n  const prompt = await getSQLPrompt(\"Tampilkan 5 tempat wisata dengan rating tertinggi\");\n  console.log(prompt); \n}\n\nmain();\n"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "customFunction_0-output-output-string|number|boolean|json|array",
                "name": "output",
                "label": "Output",
                "description": "",
                "type": "string | number | boolean | json | array"
              },
              {
                "id": "customFunction_0-output-EndingNode-CustomFunction",
                "name": "EndingNode",
                "label": "Ending Node",
                "description": "",
                "type": "CustomFunction"
              }
            ],
            "default": "output"
          }
        ],
        "outputs": {
          "output": "output"
        },
        "selected": false
      },
      "width": 300,
      "height": 725,
      "selected": false,
      "positionAbsolute": {
        "x": 597.9856956890158,
        "y": 690.7358212899138
      },
      "dragging": false
    },
    {
      "id": "promptTemplate_0",
      "position": {
        "x": 990.630925193959,
        "y": 727.5899856340397
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_0",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_0-input-template-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_0-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "Based on the provided SQL table schema and question below, return a SQL SELECT ALL query that would answer the user's question. For example: SELECT * FROM table WHERE id = '1'.\n\n-------------\nSCHEMA:\nTable: tempat_wisata\nColumns:\n- id_tempat\n- nama_tempat\n- kategori_tempat (foreign key to kategori_tempat)\n- kategori_lokasi (foreign key to kategori_lokasi)\n-lokasi\n-harga\n-deskripsi\n- rating\n- link_map\n- gambar_map\n- gambar_path\n\nTable: kategori_tempat\nColumns:\n- id_kt\n- nama_kategori_tempat (e.g., park, museum, eatery, playground)\n\nTable: kategori_lokasi\nColumns:\n- id_kl\n- nama_kategori_lokasi (e.g., jakarta, bogor, depok, bekasi, tangerang, bandung)\n\nCatatan:\n- Untuk menyaring berdasarkan lokasi, lakukan JOIN ke tabel `kategori_lokasi` dan filter berdasarkan `nama_kategori_lokasi`.\n- Untuk menyaring berdasarkan jenis tempat (misal \"museum\"), lakukan JOIN ke tabel `kategori_tempat`.\n- Jika pertanyaan mengandung kata seperti \"terbaik\", \"tertinggi\", \"terbagus\", \"paling bagus\", atau bentuk superlatif lainnya, tambahkan `ORDER BY rating DESC LIMIT 1`.\n- Jika pertanyaan menyebut angka (contoh: \"3 tempat wisata\"), gunakan angka tersebut sebagai `LIMIT`.\n- Jika tidak ada angka maupun kata superlatif, gunakan `LIMIT 3` sebagai default.\n- **Jangan sertakan kolom `link_map`, `gambar_map`, dan `gambar_path` dalam SELECT. Abaikan kolom-kolom ini.**\n\n-------------\nReturn only a valid SQL SELECT query, without any code formatting, without triple backticks, and without labels like 'sql' or 'query'. Only return the raw SQL statement, nothing else.\n-------------\nQUESTION: {question}\n-------------\nSQL QUERY:",
          "promptValues": "{\"schema\":\"{{customFunction_0.data.instance}}\",\"question\":\"{{question}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 511,
      "positionAbsolute": {
        "x": 990.630925193959,
        "y": 727.5899856340397
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "ifElseFunction_0",
      "position": {
        "x": 1860.8487326020525,
        "y": 546.0710724543775
      },
      "type": "customNode",
      "data": {
        "id": "ifElseFunction_0",
        "label": "IfElse Function",
        "version": 2,
        "name": "ifElseFunction",
        "type": "IfElseFunction",
        "baseClasses": [
          "IfElseFunction",
          "Utilities"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Split flows based on If Else javascript functions",
        "inputParams": [
          {
            "label": "Input Variables",
            "name": "functionInputVariables",
            "description": "Input variables can be used in the function with prefix $. For example: $var",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "ifElseFunction_0-input-functionInputVariables-json"
          },
          {
            "label": "IfElse Name",
            "name": "functionName",
            "type": "string",
            "optional": true,
            "placeholder": "If Condition Match",
            "id": "ifElseFunction_0-input-functionName-string"
          },
          {
            "label": "If Function",
            "name": "ifFunction",
            "description": "Function must return a value",
            "type": "code",
            "rows": 2,
            "default": "if (\"hello\" == \"hello\") {\n    return true;\n}",
            "id": "ifElseFunction_0-input-ifFunction-code"
          },
          {
            "label": "Else Function",
            "name": "elseFunction",
            "description": "Function must return a value",
            "type": "code",
            "rows": 2,
            "default": "return false;",
            "id": "ifElseFunction_0-input-elseFunction-code"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "functionInputVariables": "{\"sqlQuery\":\"{{llmChain_0.data.instance}}\"}",
          "functionName": "cek query",
          "ifFunction": "const sqlQuery = $sqlQuery.trim()\nif(sqlQuery.includes('SELECT')){\n  return sqlQuery\n}",
          "elseFunction": "return $sqlQuery"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "ifElseFunction_0-output-returnTrue-string|number|boolean|json|array",
                "name": "returnTrue",
                "label": "True",
                "description": "",
                "type": "string | number | boolean | json | array",
                "isAnchor": true
              },
              {
                "id": "ifElseFunction_0-output-returnFalse-string|number|boolean|json|array",
                "name": "returnFalse",
                "label": "False",
                "description": "",
                "type": "string | number | boolean | json | array",
                "isAnchor": true
              }
            ],
            "default": "returnTrue"
          }
        ],
        "outputs": {
          "output": "returnTrue"
        },
        "selected": false
      },
      "width": 300,
      "height": 765,
      "selected": false,
      "positionAbsolute": {
        "x": 1860.8487326020525,
        "y": 546.0710724543775
      },
      "dragging": false
    },
    {
      "id": "customFunction_1",
      "position": {
        "x": 2274.923800279097,
        "y": 865.2542390333691
      },
      "type": "customNode",
      "data": {
        "id": "customFunction_1",
        "label": "Custom JS Function",
        "version": 3,
        "name": "customFunction",
        "type": "CustomFunction",
        "baseClasses": [
          "CustomFunction",
          "Utilities"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Execute custom javascript function",
        "inputParams": [
          {
            "label": "Input Variables",
            "name": "functionInputVariables",
            "description": "Input variables can be used in the function with prefix $. For example: $var",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "customFunction_1-input-functionInputVariables-json"
          },
          {
            "label": "Function Name",
            "name": "functionName",
            "type": "string",
            "optional": true,
            "placeholder": "My Function",
            "id": "customFunction_1-input-functionName-string"
          },
          {
            "label": "Javascript Function",
            "name": "javascriptFunction",
            "type": "code",
            "id": "customFunction_1-input-javascriptFunction-code"
          }
        ],
        "inputAnchors": [
          {
            "label": "Additional Tools",
            "description": "Tools can be used in the function with $tools.{tool_name}.invoke(args)",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "customFunction_1-input-tools-Tool"
          }
        ],
        "inputs": {
          "functionInputVariables": "{\"sqlQuery\":\"{{ifElseFunction_0.data.instance}}\"}",
          "functionName": "execute Query",
          "tools": "",
          "javascriptFunction": "const HOST = 'localhost';\nconst USER = 'root';\nconst PASSWORD = '';\nconst DATABASE = 'rehatin_v2';\nconst TABLE = 'tempat_wisata';\nconst mysql = require('mysql2/promise');\n\nlet result;\n\nfunction getSQLResult() {\n  return new Promise(async (resolve, reject) => {\n    try {\n      const singleStoreConnection = mysql.createPool({\n        host: HOST,\n        user: USER,\n        password: PASSWORD,\n        database: DATABASE,\n      });\n     \n      const [rows] = await singleStoreConnection.execute(\n        $sqlQuery\n      );\n  \n      result = JSON.stringify(rows)\n      \n      resolve();\n    } catch (e) {\n      console.error(e);\n      return reject(e);\n    }\n  });\n}\n\nasync function main() {\n    await getSQLResult();\n}\n\nawait main();\n\nreturn result;"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "customFunction_1-output-output-string|number|boolean|json|array",
                "name": "output",
                "label": "Output",
                "description": "",
                "type": "string | number | boolean | json | array"
              },
              {
                "id": "customFunction_1-output-EndingNode-CustomFunction",
                "name": "EndingNode",
                "label": "Ending Node",
                "description": "",
                "type": "CustomFunction"
              }
            ],
            "default": "output"
          }
        ],
        "outputs": {
          "output": "output"
        },
        "selected": false
      },
      "width": 300,
      "height": 725,
      "selected": false,
      "positionAbsolute": {
        "x": 2274.923800279097,
        "y": 865.2542390333691
      },
      "dragging": false
    },
    {
      "id": "llmChain_1",
      "position": {
        "x": 3122.4914257624823,
        "y": 697.8464706927206
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_1",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_1-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_1-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_1-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_1-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_1-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_1.data.instance}}",
          "prompt": "{{promptTemplate_1.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": " Answer Chain"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_1-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_1-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "llmChain"
        },
        "selected": false
      },
      "width": 300,
      "height": 507,
      "selected": false,
      "positionAbsolute": {
        "x": 3122.4914257624823,
        "y": 697.8464706927206
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_1",
      "position": {
        "x": 2713.8815945479155,
        "y": 1238.767652395725
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_1",
        "label": "ChatGoogleGenerativeAI",
        "version": 3,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_1-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_1-input-modelName-asyncOptions"
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-customModelName-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-streaming-boolean"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-harmBlockThreshold-multiOptions"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-allowImageUploads-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.0-flash-001",
          "customModelName": "",
          "temperature": "0.5",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": 2713.8815945479155,
        "y": 1238.767652395725
      },
      "dragging": false
    },
    {
      "id": "promptTemplate_1",
      "position": {
        "x": 2689.166278812672,
        "y": 672.9815909323994
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_1",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_1-input-template-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_1-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "You are a helpful assistant that answers user questions based on database information only.\n\nIf the SQL response is empty, null, contains only headers, or unrelated to the question, respond with:\n\"Maaf, saya tidak bisa menjawab pertanyaan tersebut karena tidak ada informasi yang relevan di dalam database.\"\n\nOtherwise, generate a detailed and natural-sounding response in Indonesian, based on the question and the SQL response.\n\nJangan gunakan format kode atau tanda ```sql. Jawaban harus berupa teks biasa.\n\n------------\nQUESTION: {question}\n------------\nSQL RESPONSE: {sqlResponse}\n------------\nNATURAL LANGUAGE RESPONSE:\n",
          "promptValues": "{\"question\":\"{{question}}\",\"sqlResponse\":\"{{customFunction_1.data.instance}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 511,
      "selected": false,
      "positionAbsolute": {
        "x": 2689.166278812672,
        "y": 672.9815909323994
      },
      "dragging": false
    },
    {
      "id": "promptTemplate_2",
      "position": {
        "x": 2267.1929287419725,
        "y": 1643.5370117945145
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_2",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_2-input-template-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_2-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "jawab dengan saya tidak tau.",
          "promptValues": ""
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 511,
      "selected": false,
      "positionAbsolute": {
        "x": 2267.1929287419725,
        "y": 1643.5370117945145
      },
      "dragging": false
    },
    {
      "id": "llmChain_2",
      "position": {
        "x": 2715.365985200443,
        "y": 1970.7091873627694
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_2",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_2-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_2-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_2-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_2-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_2-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_2.data.instance}}",
          "prompt": "{{promptTemplate_2.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": "jawaban kurang tau"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_2-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_2-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "llmChain"
        },
        "selected": false
      },
      "width": 300,
      "height": 507,
      "selected": false,
      "positionAbsolute": {
        "x": 2715.365985200443,
        "y": 1970.7091873627694
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_2",
      "position": {
        "x": 2258.5270536062903,
        "y": 2219.192525155535
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_2",
        "label": "ChatGoogleGenerativeAI",
        "version": 3,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_2-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_2-input-modelName-asyncOptions"
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_2-input-customModelName-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_2-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_2-input-streaming-boolean"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_2-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_2-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_2-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_2-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_2-input-harmBlockThreshold-multiOptions"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_2-input-allowImageUploads-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_2-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.0-flash-001",
          "customModelName": "",
          "temperature": "0.5",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_2-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": 2258.5270536062903,
        "y": 2219.192525155535
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "promptTemplate_0",
      "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
    },
    {
      "source": "customFunction_0",
      "sourceHandle": "customFunction_0-output-output-string|number|boolean|json|array",
      "target": "promptTemplate_0",
      "targetHandle": "promptTemplate_0-input-promptValues-json",
      "type": "buttonedge",
      "id": "customFunction_0-customFunction_0-output-output-string|number|boolean|json|array-promptTemplate_0-promptTemplate_0-input-promptValues-json"
    },
    {
      "source": "llmChain_0",
      "sourceHandle": "llmChain_0-output-outputPrediction-string|json",
      "target": "ifElseFunction_0",
      "targetHandle": "ifElseFunction_0-input-functionInputVariables-json",
      "type": "buttonedge",
      "id": "llmChain_0-llmChain_0-output-outputPrediction-string|json-ifElseFunction_0-ifElseFunction_0-input-functionInputVariables-json"
    },
    {
      "source": "ifElseFunction_0",
      "sourceHandle": "ifElseFunction_0-output-returnTrue-string|number|boolean|json|array",
      "target": "customFunction_1",
      "targetHandle": "customFunction_1-input-functionInputVariables-json",
      "type": "buttonedge",
      "id": "ifElseFunction_0-ifElseFunction_0-output-returnTrue-string|number|boolean|json|array-customFunction_1-customFunction_1-input-functionInputVariables-json"
    },
    {
      "source": "customFunction_1",
      "sourceHandle": "customFunction_1-output-output-string|number|boolean|json|array",
      "target": "promptTemplate_1",
      "targetHandle": "promptTemplate_1-input-promptValues-json",
      "type": "buttonedge",
      "id": "customFunction_1-customFunction_1-output-output-string|number|boolean|json|array-promptTemplate_1-promptTemplate_1-input-promptValues-json"
    },
    {
      "source": "promptTemplate_1",
      "sourceHandle": "promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_1-promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_1-llmChain_1-input-prompt-BasePromptTemplate"
    },
    {
      "source": "chatGoogleGenerativeAI_1",
      "sourceHandle": "chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_1-chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_1-llmChain_1-input-model-BaseLanguageModel"
    },
    {
      "source": "ifElseFunction_0",
      "sourceHandle": "ifElseFunction_0-output-returnFalse-string|number|boolean|json|array",
      "target": "promptTemplate_2",
      "targetHandle": "promptTemplate_2-input-promptValues-json",
      "type": "buttonedge",
      "id": "ifElseFunction_0-ifElseFunction_0-output-returnFalse-string|number|boolean|json|array-promptTemplate_2-promptTemplate_2-input-promptValues-json"
    },
    {
      "source": "promptTemplate_2",
      "sourceHandle": "promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_2",
      "targetHandle": "llmChain_2-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_2-promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_2-llmChain_2-input-prompt-BasePromptTemplate"
    },
    {
      "source": "chatGoogleGenerativeAI_2",
      "sourceHandle": "chatGoogleGenerativeAI_2-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_2",
      "targetHandle": "llmChain_2-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_2-chatGoogleGenerativeAI_2-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_2-llmChain_2-input-model-BaseLanguageModel"
    }
  ]
}